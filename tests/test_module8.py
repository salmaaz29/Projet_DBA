# cli_test.py
"""
Interface en ligne de commande pour tester le Module 8
"""

import sys
import json

import sys
import os

# Ajouter le r√©pertoire parent au path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from colorama import init, Fore, Style
init(autoreset=True)

def print_header(text):
    print(f"\n{Fore.CYAN}{'='*60}")
    print(f"{text}")
    print(f"{'='*60}{Style.RESET_ALL}")

def print_success(text):
    print(f"{Fore.GREEN}‚úì {text}{Style.RESET_ALL}")

def print_error(text):
    print(f"{Fore.RED}‚úó {text}{Style.RESET_ALL}")

def print_info(text):
    print(f"{Fore.YELLOW}‚Ñπ {text}{Style.RESET_ALL}")

def interactive_test():
    """Test interactif en CLI"""
    
    print_header("üß™ TEST INTERACTIF - MODULE 8 RECOVERY")
    
    try:
        # Importer
        from src.llm_engine import LLMEngine
        from src.recovery_guide import OracleRecoveryGuide
        
        print_info("Initialisation du LLMEngine...")
        
        # Mock RAG
        class MockRAG:
            def retrieve_context(self, *args, **kwargs):
                return []
        
        # Essayer gemma2:2b, fallback sur tinyllama
        try:
            llm = LLMEngine(rag_setup=MockRAG(), default_model="tinyllama")
            print_success(f"LLMEngine initialis√© avec tinyllama")
        except:
            llm = LLMEngine(rag_setup=MockRAG(), default_model="tinyllama")
            print_info(f"Fallback sur tinyllama")
        
        guide = OracleRecoveryGuide(llm_engine=llm)
        print_success("OracleRecoveryGuide pr√™t")
        
        while True:
            print_header("POSER UNE QUESTION")
            print("Exemples:")
            print("  ‚Ä¢ 'Ma base a crash√©, que faire ?'")
            print("  ‚Ä¢ 'Je veux r√©cup√©rer √† hier 14h'")
            print("  ‚Ä¢ 'Table EMPLOYEES supprim√©e'")
            print("  ‚Ä¢ 'Quit' pour quitter")
            print("-" * 40)
            
            question = input(f"{Fore.BLUE}‚ùì Votre question: {Style.RESET_ALL}").strip()
            
            if question.lower() in ['quit', 'exit', 'q']:
                break
            
            if not question:
                continue
            
            print_info("Traitement en cours...")
            
            try:
                result = guide.handle_user_question(question)
                
                print(f"\n{Fore.GREEN}üìä R√âSULTAT:{Style.RESET_ALL}")
                print(f"  Sc√©nario: {result['scenario_name']}")
                print(f"  ID: {result['scenario']}")
                
                if result['needs_clarification']:
                    print(f"\n{Fore.YELLOW}‚ùì QUESTIONS DE CLARIFICATION:{Style.RESET_ALL}")
                    for i, q in enumerate(result['clarification_questions'][:3], 1):
                        print(f"  {i}. {q}")
                    
                    # Simuler des r√©ponses
                    clarifications = {}
                    if result['scenario'] == 'pitr':
                        clarifications['target_time'] = '15-MAR-2024 14:30:00'
                    elif result['scenario'] == 'table_recovery':
                        clarifications['table_name'] = 'EMPLOYEES'
                    
                    if clarifications:
                        print(f"\n{Fore.CYAN}üìã R√âPONSES SIMUL√âES:{Style.RESET_ALL}")
                        for k, v in clarifications.items():
                            print(f"  ‚Ä¢ {k}: {v}")
                        
                        # Reg√©n√©rer avec clarifications
                        print_info("G√©n√©ration du guide final...")
                        final_result = guide.handle_user_question(question, clarifications)
                        result = final_result
                
                # Afficher le guide
                guide_data = result['guide']
                print(f"\n{Fore.GREEN}üìã GUIDE G√âN√âR√â:{Style.RESET_ALL}")
                print(f"  Mod√®le: {guide_data.get('model_used', 'N/A')}")
                print(f"  Dur√©e: {guide_data.get('estimated_duration', 'N/A')}")
                
                if 'response' in guide_data:
                    print(f"\n{Fore.WHITE}üìÑ CONTENU:{Style.RESET_ALL}")
                    print(guide_data['response'][:500])
                    if len(guide_data['response']) > 500:
                        print("...")
                elif 'steps' in guide_data:
                    print(f"\n{Fore.WHITE}üìã √âTAPES ({len(guide_data['steps'])}):{Style.RESET_ALL}")
                    for step in guide_data['steps'][:3]:  # Afficher 3 premi√®res
                        print(f"  {step['step']}. {step['title']}")
                    if len(guide_data['steps']) > 3:
                        print(f"  ... et {len(guide_data['steps']) - 3} √©tapes suppl√©mentaires")
                
                print(f"\n{Fore.GREEN}‚úÖ Test r√©ussi!{Style.RESET_ALL}")
                
            except Exception as e:
                print_error(f"Erreur: {e}")
                
            input(f"\n{Fore.CYAN}‚Üµ Appuyez sur Entr√©e pour continuer...{Style.RESET_ALL}")
    
    except ImportError as e:
        print_error(f"Import impossible: {e}")
        print_info("Assurez-vous que:")
        print("  1. Vous √™tes dans le dossier du projet")
        print("  2. src/llm_engine.py existe")
        print("  3. Ollama est install√©")

if __name__ == "__main__":
    interactive_test()