# src/llm_engine.py - VERSION FINALE COMPL√àTE AVEC SCORING CORRIG√â
import ollama
import yaml
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from typing import Optional, Dict, Any
import time
import re

# Importer le RAG du Module 2
from src.rag_setup import OracleRAGSetup

class LLMEngine:
    """
    Hub central pour int√©gration LLM avec Prompt Engineering et RAG.
    Optimis√© pour gemma2:2b avec fallback tinyllama.
    """
    def __init__(self, rag_setup: OracleRAGSetup, prompts_file: str = "data/prompts.yaml", default_model: str = "gemma2:2b"):
        self.rag = rag_setup  # Instance RAG du Module 2
        self.default_model = default_model  # Maintenant gemma2:2b
        self.prompts = self._load_prompts(prompts_file)
        self.fallback_model = "tinyllama"

    def _load_prompts(self, file_path: str) -> Dict:
        """Charger tous les prompts depuis YAML."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  prompts.yaml non trouv√©, utilisation des prompts par d√©faut: {e}")
            return self._get_default_prompts()

    def _get_default_prompts(self) -> Dict:
        """Retourne des prompts par d√©faut si le fichier YAML est manquant."""
        return {
            'module4': {
                'assess_security': """Analyse de s√©curit√© Oracle :
Configuration : {config}
Identifie les risques de s√©curit√©, donne un score sur 100 et des recommandations concr√®tes.
Format de r√©ponse : 
- Score : /100
- Risques identifi√©s : liste
- Recommandations : liste"""
            },
            'module5': {
                'analyze_query': """Analyse de requ√™te SQL Oracle :
Requ√™te : {sql_query}
Plan d'ex√©cution : {plan}
Analyse les probl√®mes de performance et propose des optimisations.
Format : Explication + recommandations d'index, restructuration, etc."""
            },
            'module6': {
                'detect_anomaly': """D√©tection d'anomalie dans logs Oracle :
Entr√©e de log : {log_entry}
Analyse si c'est normal ou suspect. Justifie la classification.
Format : Classification (NORMAL/SUSPECT/CRITIQUE) + Justification"""
            }
        }

    @retry(
        retry=retry_if_exception_type(Exception),
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=5)
    )
    def generate(self, prompt: str, context: Optional[str] = None, model: Optional[str] = None, max_tokens: int = 800) -> str:
        """
        Appel LLM optimis√© pour gemma2:2b.
        Si context=None, utilise RAG pour le fetcher.
        """
        model = model or self.default_model
        
        if context is None:
            # Fetch context via RAG du Module 2
            try:
                rag_results = self.rag.retrieve_context(prompt, n_results=3, min_score=0.4)
                context = "\n".join([doc['content'][:200] for doc in rag_results]) if rag_results else ""
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur RAG: {e}")
                context = ""

        # Prompt optimis√© pour gemma2:2b
        if context:
            full_prompt = f"""Instruction : R√©ponds en fran√ßais de mani√®re concise et technique.
Contexte pertinent : {context}

Question : {prompt}

R√©ponse :"""
        else:
            full_prompt = f"""Instruction : R√©ponds en fran√ßais de mani√®re concise et technique.
Question : {prompt}

R√©ponse :"""

        try:
            # Appel Ollama avec param√®tres optimis√©s
            start_time = time.time()
            response = ollama.generate(
                model=model,
                prompt=full_prompt,
                options={
                    'num_predict': 1500,
                    'temperature': 0.4,
                    'top_p': 0.95,
                    'repeat_penalty': 1.1
                }
            )['response']
            
            elapsed = time.time() - start_time
            if elapsed > 25:
                print(f"‚ö†Ô∏è  R√©ponse lente: {elapsed:.1f}s")
            
            return response.strip()
            
        except Exception as e:
            print(f"‚ùå Erreur LLM ({model}): {e} ‚Üí Fallback √† {self.fallback_model}")
            try:
                # Fallback avec tinyllama - prompt simplifi√©
                fallback_prompt = f"Q: {prompt[:500]}\nA (en fran√ßais, court):"
                response = ollama.generate(
                    model=self.fallback_model,
                    prompt=fallback_prompt,
                    options={'num_predict': min(300, max_tokens), 'temperature': 0.4}
                )['response']
                return f"[tinyllama fallback] {response.strip()}"
            except Exception as fallback_error:
                print(f"‚ùå Fallback aussi en √©chec: {fallback_error}")
                return f"[Erreur] Aucun mod√®le disponible. Installez au moins 'gemma2:2b' ou 'tinyllama'."

    def analyze_query(self, sql_query: str, plan: str) -> Dict[str, Any]:
        """Pour Module 5: Optimisation de requ√™tes."""
        try:
            prompt_template = self.prompts.get('module5', {}).get('analyze_query', 
                "Analyse cette requ√™te SQL: {sql_query}\nPlan: {plan}\nSuggestions:")
            prompt = prompt_template.format(sql_query=sql_query, plan=plan)
            response = self.generate(prompt, max_tokens=600)
            
            return {
                "explanation": response,
                "recommendations": self._extract_recommendations(response),
                "model_used": self.default_model
            }
        except Exception as e:
            return {"error": str(e), "explanation": "Erreur d'analyse"}

    def _extract_recommendations(self, text: str) -> list:
        """Extrait les recommandations de la r√©ponse - VERSION AM√âLIOR√âE."""
        recommendations = []
        lines = text.split('\n')
        
        # Mots-cl√©s de recommandations
        rec_keywords = ['recommande', 'sugg√®re', 'devrait', 'conseil', 'il faut', 
                        'restreindre', 'limiter', 'cr√©er', 'ajouter', 'utiliser',
                        'configurer', 'activer', 'd√©sactiver']
        
        for line in lines:
            line_clean = line.strip()
            line_lower = line_clean.lower()
            
            # Ignorer lignes trop courtes
            if len(line_clean) < 15:
                continue
            
            # Si ligne commence par bullet ou num√©ro
            if line_clean.startswith(('-', '‚Ä¢', '*')) or (line_clean and line_clean[0].isdigit()):
                clean = line_clean.lstrip('-‚Ä¢*0123456789. ').strip()
                if len(clean) > 15:
                    recommendations.append(clean)
            # Ou si contient mot-cl√© de recommandation
            elif any(keyword in line_lower for keyword in rec_keywords):
                # Ne pas ajouter si c'est un header
                if ':' not in line_clean[:30]:
                    recommendations.append(line_clean)
        
        return recommendations[:10]  # Max 10

    def assess_security(self, config: str) -> Dict[str, Any]:
        """Pour Module 4: Audit s√©curit√© - VERSION FINALE AVEC SCORING PAR R√àGLES."""
        try:
            # Prompt optimis√© avec instructions STRICTES sur le scoring
            prompt_optimise = f"""Tu es un expert en s√©curit√© Oracle Database.

CONFIGURATION √Ä ANALYSER :
{config}

INSTRUCTIONS IMPORTANTES :
- Un utilisateur avec DBA = TR√àS DANGEREUX ‚Üí Score < 40
- CREATE ANY TABLE / SELECT ANY TABLE = DANGEREUX ‚Üí Score < 60
- Mot de passe sans expiration = RISQUE ‚Üí -20 points
- Chaque privil√®ge excessif = -15 points

R√âPONSE REQUISE (suis ce format EXACTEMENT, une ligne par item) :

SCORE: [nombre entre 0 et 100]

RISQUES D√âTECT√âS:
- Privil√®ge DBA accorde un acc√®s administrateur complet
- CREATE ANY TABLE permet cr√©ation dans tous les sch√©mas
- SELECT ANY TABLE donne acc√®s √† toutes les donn√©es
- Mot de passe sans expiration facilite les attaques

RECOMMANDATIONS:
- R√©voquer le privil√®ge DBA imm√©diatement
- Limiter √† CREATE TABLE dans le sch√©ma propri√©taire uniquement
- Configurer PASSWORD_LIFE_TIME √† 90 jours
- Impl√©menter le principe du moindre privil√®ge

R√©ponds en fran√ßais. IMPORTANT : Sois S√âV√àRE dans ton scoring."""

            # G√©n√©ration
            response = self.generate(prompt_optimise, max_tokens=700)
            
            # √âTAPE 1 : Calcul du score par R√àGLES (plus fiable que LLM)
            config_lower = config.lower()
            score = 100  # Score de d√©part parfait
            
            # P√©nalit√©s automatiques bas√©es sur mots-cl√©s
            if 'dba' in config_lower:
                score -= 40  # TR√àS S√âV√àRE : acc√®s complet
            if 'create any table' in config_lower:
                score -= 20  # Peut cr√©er partout
            if 'select any table' in config_lower:
                score -= 20  # Peut lire partout
            if 'drop any' in config_lower:
                score -= 15  # Peut supprimer partout
            if "n'expire" in config_lower or 'never expire' in config_lower or 'jamais' in config_lower:
                score -= 15  # Mot de passe √©ternel
            if 'unlimited tablespace' in config_lower:
                score -= 10  # Peut remplir le disque
            if 'sysdba' in config_lower or 'sysoper' in config_lower:
                score -= 30  # Privil√®ges syst√®me
            
            # S'assurer que le score reste dans [0, 100]
            score = max(0, min(100, score))
            
            # √âTAPE 2 : Extraction des RISQUES avec parsing am√©lior√©
            risks = []
            
            # Chercher la section RISQUES D√âTECT√âS
            risk_section = re.search(r'RISQUES[^:]*:(.*?)(?=RECOMMANDATIONS|ANALYSE|$)', 
                                     response, re.IGNORECASE | re.DOTALL)
            
            if risk_section:
                risk_text = risk_section.group(1)
                for line in risk_text.split('\n'):
                    line = line.strip()
                    # Extraire les lignes avec bullets
                    if line.startswith(('-', '‚Ä¢', '*', '‚Äì')):
                        clean_risk = line.lstrip('-‚Ä¢*‚Äì ').strip()
                        # Retirer les "**" markdown
                        clean_risk = re.sub(r'\*\*', '', clean_risk)
                        # Retirer les deux-points et texte apr√®s si pattern "Titre: Description"
                        if ':' in clean_risk:
                            parts = clean_risk.split(':', 1)
                            if len(parts[0]) > 50:  # Si titre long, garder tout
                                clean_risk = clean_risk
                            else:  # Sinon prendre la description apr√®s ":"
                                clean_risk = parts[1].strip() if len(parts) > 1 else parts[0]
                        
                        if len(clean_risk) > 15:  # Ignorer trop court
                            risks.append(clean_risk)
            
            # Fallback : chercher dans tout le texte si section non trouv√©e
            if not risks:
                risk_keywords = ['dba', 'privil√®ge', 'any table', 'expire', 'risque', 'vuln√©rabilit√©', 'danger']
                for line in response.split('\n'):
                    if any(kw in line.lower() for kw in risk_keywords):
                        clean = line.strip().lstrip('-‚Ä¢*‚Äì ')
                        clean = re.sub(r'\*\*', '', clean)
                        if 15 < len(clean) < 300:  # Longueur raisonnable
                            risks.append(clean)
            
            # √âTAPE 3 : Extraction des RECOMMANDATIONS
            recommendations = []
            
            rec_section = re.search(r'RECOMMANDATIONS[^:]*:(.*?)(?=ANALYSE|$)', 
                                   response, re.IGNORECASE | re.DOTALL)
            
            if rec_section:
                rec_text = rec_section.group(1)
                for line in rec_text.split('\n'):
                    line = line.strip()
                    if line.startswith(('-', '‚Ä¢', '*', '‚Äì')) or (line and line[0].isdigit()):
                        clean_rec = line.lstrip('-‚Ä¢*‚Äì0123456789. ').strip()
                        clean_rec = re.sub(r'\*\*', '', clean_rec)
                        
                        # Retirer pr√©fixes type "Exemple:", "Note:", etc.
                        if ':' in clean_rec[:30]:
                            parts = clean_rec.split(':', 1)
                            if parts[0].strip() in ['Exemple', 'Note', 'Important']:
                                clean_rec = parts[1].strip() if len(parts) > 1 else clean_rec
                        
                        if len(clean_rec) > 15:
                            recommendations.append(clean_rec)
            
            # Fallback pour recommandations
            if not recommendations:
                rec_keywords = ['recommande', 'devrait', 'r√©voquer', 'limiter', 'configurer', 
                               'impl√©menter', 'activer', 'd√©sactiver', 'restreindre']
                for line in response.split('\n'):
                    if any(kw in line.lower() for kw in rec_keywords):
                        clean = line.strip().lstrip('-‚Ä¢*‚Äì ')
                        clean = re.sub(r'\*\*', '', clean)
                        if 15 < len(clean) < 300 and ':' not in clean[:20]:
                            recommendations.append(clean)
            
            # √âTAPE 4 : Extraction de l'analyse g√©n√©rale
            analysis = response[:500]
            analysis_match = re.search(r'ANALYSE[^:]*:(.*)', response, re.IGNORECASE | re.DOTALL)
            if analysis_match:
                analysis = analysis_match.group(1).strip()[:500]
            
            return {
                "score": score,  # ‚≠ê Score calcul√© par R√àGLES (fiable)
                "risks": risks[:10],  # Max 10 risques
                "recommendations": recommendations[:10],  # Max 10 recommandations
                "analysis": analysis,
                "model_used": self.default_model,
                "scoring_method": "rule-based"  # Indiquer m√©thode de calcul
            }
            
        except Exception as e:
            print(f"‚ùå Erreur assess_security: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e), "score": 0, "risks": [], "recommendations": []}

    def _extract_risks(self, text: str) -> list:
        """Extrait les risques identifi√©s."""
        risks = []
        lines = text.split('\n')
        for line in lines:
            line_lower = line.lower()
            if any(risk_word in line_lower for risk_word in 
                   ['risque', 'vuln√©rabilit√©', 'danger', 'probl√®me', 'faible', 'critique']):
                if 'score' not in line_lower:
                    risks.append(line.strip())
        return risks[:5]

    def detect_anomaly(self, log_entry: str, context: Optional[str] = None) -> Dict[str, Any]:
        """Pour Module 6: D√©tection anomalies - VERSION AM√âLIOR√âE avec r√®gles."""
        
        # √âTAPE 1 : Classification par R√àGLES (plus fiable que LLM)
        log_lower = log_entry.lower()
        classification = "NORMAL"
        severity = "BASSE"
        
        # Dictionnaire des erreurs critiques Oracle
        critical_errors = {
            'ora-00600': ('CRITIQUE', 'CRITIQUE', 'Erreur interne Oracle - N√©cessite support Oracle'),
            'ora-00700': ('CRITIQUE', 'CRITIQUE', 'Soft internal error - V√©rifier alertes'),
            'ora-01555': ('CRITIQUE', 'HAUTE', 'Snapshot too old - Augmenter UNDO_RETENTION'),
            'ora-01652': ('CRITIQUE', 'HAUTE', 'Tablespace temporaire plein - Augmenter TEMP'),
            'ora-00257': ('CRITIQUE', 'CRITIQUE', 'Archiver error - Espace disque insuffisant'),
            'ora-27037': ('CRITIQUE', 'HAUTE', 'Erreur I/O fichier - V√©rifier disque'),
            'tns-12535': ('CRITIQUE', 'HAUTE', 'Timeout r√©seau - V√©rifier connectivit√©'),
            'tns-12560': ('CRITIQUE', 'HAUTE', 'Erreur adaptateur protocole'),
        }
        
        suspect_errors = {
            'ora-00942': ('SUSPECT', 'MOYENNE', 'Table inexistante ou privil√®ges manquants'),
            'ora-01017': ('SUSPECT', 'MOYENNE', 'Login/password invalide - Possible attaque'),
            'ora-12154': ('SUSPECT', 'BASSE', 'TNS service name non r√©solu'),
            'ora-28000': ('SUSPECT', 'MOYENNE', 'Compte verrouill√© - Tentatives login multiples'),
        }
        
        # V√©rifier les erreurs
        justification_rule = None
        for error_code, (classif, sev, justif) in critical_errors.items():
            if error_code in log_lower:
                classification = classif
                severity = sev
                justification_rule = justif
                break
        
        if not justification_rule:
            for error_code, (classif, sev, justif) in suspect_errors.items():
                if error_code in log_lower:
                    classification = classif
                    severity = sev
                    justification_rule = justif
                    break
        
        # √âTAPE 2 : Si r√®gle trouv√©e, retourner directement (plus rapide et fiable)
        if justification_rule:
            return {
                "classification": classification,
                "justification": justification_rule,
                "severity": severity,
                "confidence": "high",  # Haute confiance car bas√© sur r√®gles
                "model_used": "rule-based",
                "log_entry": log_entry[:100]
            }
        
        # √âTAPE 3 : Si pas de r√®gle, utiliser le LLM (pour cas complexes)
        try:
            prompt_detect = f"""Analyse ce log Oracle :

LOG: {log_entry}

Est-ce NORMAL, SUSPECT ou CRITIQUE ?

R√âPONSE REQUISE (format exact) :
CLASSIFICATION: [NORMAL ou SUSPECT ou CRITIQUE]
JUSTIFICATION: [Explique en 1-2 phrases]

R√©ponds en fran√ßais."""

            response = self.generate(prompt_detect, context=context, max_tokens=300)
            
            # Parsing de la r√©ponse LLM
            response_lower = response.lower()
            
            # Extraction classification
            class_match = re.search(r'CLASSIFICATION\s*:\s*(\w+)', response, re.IGNORECASE)
            if class_match:
                classification = class_match.group(1).upper()
            else:
                # Fallback : chercher mots-cl√©s
                if 'critique' in response_lower or 'critical' in response_lower:
                    classification = "CRITIQUE"
                elif 'suspect' in response_lower or 'anormal' in response_lower:
                    classification = "SUSPECT"
                else:
                    classification = "NORMAL"
            
            # Extraction justification
            justif_match = re.search(r'JUSTIFICATION\s*:\s*(.+)', response, re.IGNORECASE | re.DOTALL)
            justification = justif_match.group(1).strip()[:200] if justif_match else response[:200]
            
            # Inf√©rer s√©v√©rit√©
            severity_map = {'CRITIQUE': 'CRITIQUE', 'SUSPECT': 'MOYENNE', 'NORMAL': 'BASSE'}
            severity = severity_map.get(classification, 'MOYENNE')
            
            return {
                "classification": classification,
                "justification": justification,
                "severity": severity,
                "confidence": "medium",  # Confiance moyenne car LLM
                "model_used": self.default_model
            }
        
        except Exception as e:
            print(f"‚ùå Erreur LLM detect_anomaly: {e}")
            # Fallback final
            return {
                "classification": "NORMAL",
                "justification": f"Impossible d'analyser ce log. Erreur: {str(e)[:50]}",
                "severity": "BASSE",
                "confidence": "low",
                "error": str(e)
            }


# Test optimis√©
if __name__ == "__main__":
    try:
        rag = OracleRAGSetup(namespace="module2")
        engine = LLMEngine(rag_setup=rag, default_model="gemma2:2b")
        
        print("üîß Test LLM Engine avec gemma2:2b et fallback tinyllama")
        print("=" * 50)
        
        # Test 1
        test_response = engine.generate(
            "Explique ce plan d'ex√©cution en termes simples", 
            context="Exemple plan: FULL TABLE SCAN sur table EMPLOYES avec 1M lignes",
            max_tokens=1500
        )
        print(f"Test 1 - R√©ponse ({len(test_response)} chars):")
        print(test_response[:200] + "..." if len(test_response) > 200 else test_response)
        print()
        
        # Test 2
        security_test = engine.assess_security("Utilisateur TEST avec privilege DBA")
        print(f"Test 2 - Audit s√©curit√©: Score {security_test.get('score', 'N/A')}")
        print(f"Risques: {security_test.get('risks', [])[:2]}")
        
        # Test 3 - D√©tection d'anomalie
        print("\nTest 3 - D√©tection d'anomalie:")
        anomaly_logs = [
            "ORA-01555: snapshot too old - rollback segment too small",
            "Completed: ALTER DATABASE OPEN",
            "TNS-12535: TNS:operation timed out"
        ]
        
        for log in anomaly_logs:
            result = engine.detect_anomaly(log)
            print(f"  Log: {log[:50]}...")
            print(f"    ‚Üí Classification: {result.get('classification')}")
            print(f"    ‚Üí Confiance: {result.get('confidence')}")
            print()
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation: {e}")
        print("Test avec mock RAG...")
        class MockRAG:
            def retrieve_context(self, query, n_results=4, min_score=0.25):
                return [{'content': 'Oracle Database - Syst√®me de gestion de base de donn√©es relationnelle'}]
        
        engine = LLMEngine(rag_setup=MockRAG(), default_model="gemma2:2b")
        test = engine.generate("Qu'est-ce qu'Oracle?")
        print(f"Test mock: {test[:100]}...")