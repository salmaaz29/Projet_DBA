"""
MODULE 4 : Audit de S√©curit√© Automatis√© - Oracle AI Platform

√âvalue les risques de s√©curit√© Oracle en analysant :
- Utilisateurs et r√¥les applicatifs
- Privil√®ges syst√®me critiques
- Profils de mots de passe
- Configurations de s√©curit√©

G√©n√®re un rapport JSON avec score s√©curit√©, risques identifi√©s et recommandations.
Utilise les fichiers CSV extraits par data_extractor.py
"""

import json
import logging
import pandas as pd
import os
from datetime import datetime
from typing import Dict, Any, List, Optional
from llm_engine import LLMEngine

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SecurityAudit:
    """
    Comprehensive security audit class for Oracle databases.

    Uses LLM-powered analysis to assess security configurations and provide
    actionable recommendations based on Oracle best practices.
    """

    def __init__(self, llm_engine: LLMEngine, data_dir: str = "data"):
        """
        Initialize Security Audit.

        Args:
            llm_engine: Configured LLMEngine instance
            data_dir: Directory containing CSV files from extractor
        """
        self.llm_engine = llm_engine
        self.data_dir = data_dir
        self.audit_results = {}

    def load_security_data_from_csv(self) -> Dict[str, Any]:
        """
        Load security configuration from CSV files generated by data_extractor.py
        
        Returns:
            Security configuration dictionary
        """
        logger.info("Loading security data from CSV files...")
        
        config = {
            'users': [],
            'privileges': [],
            'profiles': [],
            'roles': [],
            'source': 'CSV files from Module 1',
            'loaded_date': datetime.now().isoformat()
        }
        
        try:
            # Load users data
            users_path = os.path.join(self.data_dir, "security_users.csv")
            if os.path.exists(users_path):
                users_df = pd.read_csv(users_path)
                config['users'] = users_df.to_dict('records')
                logger.info(f"Loaded {len(config['users'])} users from CSV")
            else:
                logger.warning(f"Users CSV not found: {users_path}")
            
            # Load privileges data
            privileges_path = os.path.join(self.data_dir, "security_privileges.csv")
            if os.path.exists(privileges_path):
                privileges_df = pd.read_csv(privileges_path)
                config['privileges'] = privileges_df.to_dict('records')
                logger.info(f"Loaded {len(config['privileges'])} privileges from CSV")
            else:
                logger.warning(f"Privileges CSV not found: {privileges_path}")
            
            # Load profiles data
            profiles_path = os.path.join(self.data_dir, "security_profiles.csv")
            if os.path.exists(profiles_path):
                profiles_df = pd.read_csv(profiles_path)
                config['profiles'] = profiles_df.to_dict('records')
                logger.info(f"Loaded {len(config['profiles'])} profiles from CSV")
            else:
                logger.warning(f"Profiles CSV not found: {profiles_path}")
            
            # Load roles data
            roles_path = os.path.join(self.data_dir, "security_roles.csv")
            if os.path.exists(roles_path):
                roles_df = pd.read_csv(roles_path)
                config['roles'] = roles_df.to_dict('records')
                logger.info(f"Loaded {len(config['roles'])} roles from CSV")
            else:
                logger.warning(f"Roles CSV not found: {roles_path}")
            
            return config
            
        except Exception as e:
            logger.error(f"Error loading CSV files: {e}")
            return config

    def audit_users_roles(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Audit users and roles for security risks.

        Args:
            config: Security configuration containing users and roles

        Returns:
            Audit results with risks and recommendations
        """
        logger.info("Starting users and roles audit")

        try:
            # Format CSV data for LLM analysis
            formatted_config = self._format_csv_data_for_llm(config)
            
            # Use existing assess_security method from LLMEngine
            assessment = self.llm_engine.assess_security(formatted_config)

            result = {
                'component': 'users_roles',
                'assessment': assessment,
                'status': 'completed',
                'timestamp': self._get_timestamp(),
                'data_source': 'CSV files'
            }

            self.audit_results['users_roles'] = result
            logger.info("Users and roles audit completed from CSV")
            return result

        except Exception as e:
            logger.error(f"Error in users and roles audit: {e}")
            result = {
                'component': 'users_roles',
                'assessment': f"Error: {str(e)}",
                'status': 'failed',
                'timestamp': self._get_timestamp()
            }
            self.audit_results['users_roles'] = result
            return result

    def audit_privileges(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Audit system privileges for excessive grants.

        Args:
            config: Security configuration containing privileges

        Returns:
            Audit results with privilege analysis
        """
        logger.info("Starting privileges audit from CSV")

        try:
            # Format privileges data from CSV for LLM
            privileges_data = self._format_privileges_from_csv(config)

            # Use LLM to analyze privileges
            prompt_template = self.llm_engine.prompts.get('security_audit', {}).get('analyze_privileges', '')
            if not prompt_template:
                prompt_template = "Analyse ces privil√®ges syst√®me Oracle : {privileges_data}"

            prompt = prompt_template.format(privileges_data=privileges_data)
            assessment = self.llm_engine.generate(prompt)

            result = {
                'component': 'privileges',
                'assessment': assessment,
                'status': 'completed',
                'timestamp': self._get_timestamp(),
                'data_source': 'CSV files'
            }

            self.audit_results['privileges'] = result
            logger.info("Privileges audit completed from CSV")
            return result

        except Exception as e:
            logger.error(f"Error in privileges audit: {e}")
            result = {
                'component': 'privileges',
                'assessment': f"Error: {str(e)}",
                'status': 'failed',
                'timestamp': self._get_timestamp()
            }
            self.audit_results['privileges'] = result
            return result

    def audit_profiles(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Audit password profiles for security strength.

        Args:
            config: Security configuration containing profiles

        Returns:
            Audit results with profile analysis
        """
        logger.info("Starting profiles audit from CSV")

        try:
            # Format profiles data from CSV for LLM
            profiles_data = self._format_profiles_from_csv(config)

            # Use LLM to analyze profiles
            prompt_template = self.llm_engine.prompts.get('security_audit', {}).get('analyze_profiles', '')
            if not prompt_template:
                prompt_template = "Analyse ces profils de s√©curit√© Oracle : {profile_data}"

            prompt = prompt_template.format(profile_data=profiles_data)
            assessment = self.llm_engine.generate(prompt)

            result = {
                'component': 'profiles',
                'assessment': assessment,
                'status': 'completed',
                'timestamp': self._get_timestamp(),
                'data_source': 'CSV files'
            }

            self.audit_results['profiles'] = result
            logger.info("Profiles audit completed from CSV")
            return result

        except Exception as e:
            logger.error(f"Error in profiles audit: {e}")
            result = {
                'component': 'profiles',
                'assessment': f"Error: {str(e)}",
                'status': 'failed',
                'timestamp': self._get_timestamp()
            }
            self.audit_results['profiles'] = result
            return result

    def generate_full_report(self) -> str:
        """
        Generate comprehensive security audit report using CSV data and LLM for JSON output.

        Returns:
            Complete audit report as JSON string
        """
        logger.info("Generating full security audit report from CSV data")

        # Load data from CSV files
        config = self.load_security_data_from_csv()

        if not config['users'] and not config['privileges']:
            logger.warning("No security data found in CSV files")
            return "No security data available. Run data_extractor.py first."

        # Use the new full security audit prompt for JSON output
        try:
            formatted_config = self._format_csv_data_for_llm(config)

            prompt_template = self.llm_engine.prompts.get('security_audit', {}).get('full_security_audit', '')
            if not prompt_template:
                logger.error("Full security audit prompt not found")
                return "Error: Full security audit prompt not configured"

            prompt = prompt_template.format(full_config_data=formatted_config)

            # Get LLM response
            llm_response = self.llm_engine.generate(prompt)

            # Parse and validate JSON response
            audit_data = self._parse_and_validate_audit_json(llm_response)

            if audit_data:
                # Save to JSON file
                output_path = self.save_report_to_json(audit_data)
                logger.info(f"Full security audit report generated and saved to {output_path}")
                return json.dumps(audit_data, indent=2, ensure_ascii=False)
            else:
                logger.error("Failed to generate valid audit JSON")
                return "Error: Failed to generate valid security audit report"

        except Exception as e:
            logger.error(f"Error generating full security audit report: {e}")
            return f"Error generating security audit report: {str(e)}"

    def _format_csv_data_for_llm(self, config: Dict[str, Any]) -> str:
        """
        Format CSV data for LLM analysis.

        Args:
            config: Security config from CSV

        Returns:
            Formatted text for LLM
        """
        lines = ["=== CONFIGURATION S√âCURIT√â ORACLE (CSV Source) ==="]
        
        # Users section
        if config.get('users'):
            lines.append("\nUTILISATEURS:")
            for i, user in enumerate(config['users'][:10], 1):
                username = user.get('USERNAME', 'Unknown')
                status = user.get('ACCOUNT_STATUS', 'Unknown')
                profile = user.get('PROFILE', 'Unknown')
                roles = user.get('ROLES', 'None')
                lines.append(f"{i}. {username} | Status: {status} | Profil: {profile} | R√¥les: {roles}")
        
        # Privileges section
        if config.get('privileges'):
            lines.append("\nPRIVIL√àGES SYST√àME:")
            for i, priv in enumerate(config['privileges'][:10], 1):
                grantee = priv.get('GRANTEE', 'Unknown')
                privilege = priv.get('PRIVILEGE', 'Unknown')
                admin_option = priv.get('ADMIN_OPTION', 'NO')
                lines.append(f"{i}. {grantee} ‚Üí {privilege} (Admin: {admin_option})")
        
        # Profiles section
        if config.get('profiles'):
            lines.append("\nPROFILS DE S√âCURIT√â:")
            profiles_summary = {}
            for profile in config['profiles']:
                profile_name = profile.get('PROFILE', 'Unknown')
                parameter = profile.get('PARAMETER', 'Unknown')
                value = profile.get('VALUE', 'Unknown')
                
                if profile_name not in profiles_summary:
                    profiles_summary[profile_name] = []
                profiles_summary[profile_name].append(f"{parameter}={value}")
            
            for profile_name, params in list(profiles_summary.items())[:5]:
                lines.append(f"‚Ä¢ {profile_name}: {', '.join(params[:3])}")
        
        # Roles section
        if config.get('roles'):
            lines.append("\nR√îLES PERSONNALIS√âS:")
            roles_summary = {}
            for role in config['roles'][:10]:
                role_name = role.get('ROLE', 'Unknown')
                privilege = role.get('PRIVILEGE', 'None')
                role_type = role.get('TYPE', 'Unknown')
                
                if role_name not in roles_summary:
                    roles_summary[role_name] = []
                if privilege:
                    roles_summary[role_name].append(f"{privilege} ({role_type})")
            
            for role_name, privs in list(roles_summary.items())[:5]:
                lines.append(f"‚Ä¢ {role_name}: {', '.join(privs[:2])}")
        
        lines.append(f"\nTotal users: {len(config.get('users', []))}")
        lines.append(f"Total privileges: {len(config.get('privileges', []))}")
        lines.append(f"Total profiles: {len(config.get('profiles', []))}")
        lines.append(f"Data source: {config.get('source', 'CSV files')}")
        
        return "\n".join(lines)

    def _format_privileges_from_csv(self, config: Dict[str, Any]) -> str:
        """
        Format privileges data from CSV for LLM analysis.

        Args:
            config: Security config

        Returns:
            Formatted privileges text
        """
        lines = ["PRIVIL√àGES SYST√àME DANGEREUX (CSV Source):"]
        
        if 'privileges' in config:
            for i, priv in enumerate(config['privileges'][:15], 1):
                grantee = priv.get('GRANTEE', 'UNKNOWN')
                privilege = priv.get('PRIVILEGE', 'UNKNOWN')
                admin_option = priv.get('ADMIN_OPTION', 'NO')
                
                # Highlight dangerous privileges
                danger_level = "‚ö†Ô∏è "
                if 'ANY' in str(privilege).upper():
                    danger_level = "üî¥ "
                elif 'CREATE' in str(privilege).upper() or 'DROP' in str(privilege).upper():
                    danger_level = "üü† "
                elif 'SELECT' in str(privilege).upper():
                    danger_level = "üü° "
                
                lines.append(f"{danger_level}{i}. {grantee}: {privilege} (Admin: {admin_option})")
        else:
            lines.append("Aucun privil√®ge trouv√© dans les fichiers CSV.")
        
        lines.append(f"\nTotal: {len(config.get('privileges', []))} privil√®ges analys√©s")
        
        return "\n".join(lines)

    def _format_profiles_from_csv(self, config: Dict[str, Any]) -> str:
        """
        Format profiles data from CSV for LLM analysis.

        Args:
            config: Security config

        Returns:
            Formatted profiles text
        """
        lines = ["PROFILS DE MOT DE PASSE (CSV Source):"]
        
        if 'profiles' in config and config['profiles']:
            # Group by profile name
            profiles_dict = {}
            for profile in config['profiles']:
                profile_name = profile.get('PROFILE', 'DEFAULT')
                parameter = profile.get('PARAMETER', '')
                value = profile.get('VALUE', '')
                
                if profile_name not in profiles_dict:
                    profiles_dict[profile_name] = []
                
                if parameter and value:
                    profiles_dict[profile_name].append(f"{parameter}={value}")
            
            for profile_name, params in list(profiles_dict.items())[:5]:
                lines.append(f"\nüìã Profil: {profile_name}")
                for param in params[:6]:
                    lines.append(f"  ‚Ä¢ {param}")
        else:
            lines.append("Aucun profil de s√©curit√© trouv√© dans les fichiers CSV.")
        
        return "\n".join(lines)

    def _compile_report(self) -> str:
        """
        Compile all audit results into a comprehensive report.

        Returns:
            Formatted audit report
        """
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ORACLE DATABASE SECURITY AUDIT REPORT")
        report_lines.append("Source: CSV files generated by Module 1 (data_extractor.py)")
        report_lines.append("=" * 80)
        report_lines.append("")

        # Summary
        completed_audits = sum(1 for result in self.audit_results.values() if result['status'] == 'completed')
        total_audits = len(self.audit_results)
        report_lines.append(f"üìä Audit Summary: {completed_audits}/{total_audits} components completed")
        
        # Data source information
        if self.audit_results:
            first_result = next(iter(self.audit_results.values()))
            if 'data_source' in first_result:
                report_lines.append(f"üìÅ Data Source: {first_result['data_source']}")
        
        report_lines.append("")

        # Individual component reports
        for component, result in self.audit_results.items():
            report_lines.append("-" * 60)
            report_lines.append(f"üîç Component: {component.upper().replace('_', ' ')}")
            report_lines.append(f"‚úÖ Status: {result['status']}")
            report_lines.append(f"üïí Timestamp: {result['timestamp']}")
            report_lines.append("")
            report_lines.append("Assessment:")
            report_lines.append(str(result['assessment']))
            report_lines.append("")

        # Recommendations section
        report_lines.append("-" * 60)
        report_lines.append("üí° OVERALL RECOMMENDATIONS")
        report_lines.append("-" * 60)
        report_lines.append("")
        report_lines.append("1. üîê Review all flagged security risks and implement remediation steps")
        report_lines.append("2. üõ°Ô∏è Implement least privilege principle for all users and roles")
        report_lines.append("3. üìã Regularly review and audit security configurations")
        report_lines.append("4. üëÅÔ∏è Enable comprehensive auditing for sensitive operations")
        report_lines.append("5. üîí Use Oracle best practices for encryption and access control")
        report_lines.append("6. üóÇÔ∏è Maintain proper documentation of security policies")
        report_lines.append("")

        report_lines.append("=" * 80)
        report_lines.append("End of Security Audit Report")
        report_lines.append("=" * 80)

        return "\n".join(report_lines)

    def _get_timestamp(self) -> str:
        """
        Get current timestamp for audit records.

        Returns:
            ISO format timestamp
        """
        return datetime.now().isoformat()

    def get_audit_summary(self) -> Dict[str, Any]:
        """
        Get summary of audit results.

        Returns:
            Summary dictionary
        """
        total_components = len(self.audit_results)
        completed = sum(1 for result in self.audit_results.values() if result['status'] == 'completed')
        failed = sum(1 for result in self.audit_results.values() if result['status'] == 'failed')

        return {
            'total_components': total_components,
            'completed': completed,
            'failed': failed,
            'success_rate': completed / total_components if total_components > 0 else 0,
            'data_source': 'CSV files from Module 1'
        }

    def save_report_to_json(self, audit_data: Dict[str, Any], output_path: str = "reports/security_audit.json"):
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        report_data = {
            'metadata': {
                'module': 'Module 4 - Security Audit',
                'generated_at': self._get_timestamp(),
                'data_source': 'CSV files from Module 1',
                'llm_engine': self.llm_engine.__class__.__name__
            },
            'audit_results': audit_data
        }

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            logger.info(f"Report saved to {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error saving report: {e}")
            return None
    

    def _parse_and_validate_audit_json(self, llm_response: str) -> dict:
        """
        Essaye de parser la r√©ponse LLM en JSON valide.
        Si √©chec, retourne None.
        """
        try:
            data = json.loads(llm_response)
            return data
        except json.JSONDecodeError:
            logger.warning("LLM response is not valid JSON, returning empty dict")
            return {}
        

    def _parse_and_validate_audit_json(self, llm_response: str) -> dict:
        """
        Parse LLM response and ensure it's valid JSON.
        Remove code formatting backticks if present.
        """
        import re
        try:
            # Remove ```json ... ``` wrapper
            cleaned_response = re.sub(r"^```json\s*|\s*```$", "", llm_response.strip(), flags=re.MULTILINE)
            return json.loads(cleaned_response)
        except json.JSONDecodeError:
            logger.warning("LLM response is not valid JSON, returning raw text instead")
            return {"raw_text": llm_response}

       


if __name__ == "__main__":
    # Cr√©e une instance de LLMEngine (adapt√©e √† ton projet)
    llm_engine = LLMEngine()  # Assure-toi que LLMEngine fonctionne et est configur√©

    # Cr√©e l‚Äôaudit
    audit = SecurityAudit(llm_engine=llm_engine, data_dir="data")

    # G√©n√®re le rapport complet
    report_json = audit.generate_full_report()

    # Affiche le r√©sultat √† l‚Äô√©cran
    print(report_json)
